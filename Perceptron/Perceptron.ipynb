{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Perceptron.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPEMK7dYH2boz+xbQxAcatJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/athtowfiq/NeuralNetwork/blob/main/Perceptron/Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuRyAsbTJVkT"
      },
      "source": [
        "**Perceptron Question 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92qmFIPO7lOj",
        "outputId": "6213d948-00e0-43df-ff54-3af2fb0d48b7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pd0YO5D_8kLR",
        "outputId": "54bf5392-d52d-439c-fe62-86f274eebae2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "random.seed(100)\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Perceptron/train.txt', sep=' ', header=None)\n",
        "df = df.values\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1. ,  1. ,  1. ],\n",
              "       [ 1. , -1. ,  1. ],\n",
              "       [ 4. ,  5. ,  1. ],\n",
              "       [ 2. ,  2.5,  2. ],\n",
              "       [ 0. ,  2. ,  2. ],\n",
              "       [ 2. ,  3. ,  2. ]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "y0bXM_ZbBJZ3",
        "outputId": "f293f790-4127-4e7a-a4e9-cbe6108e9e67"
      },
      "source": [
        "for data in df:\n",
        "    if data[2] == 1:\n",
        "        plt.scatter(data[0], data[1], marker='*', color='red')\n",
        "    else:\n",
        "        plt.scatter(data[0], data[1], marker='+', color='blue')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5TCjVXzJowB"
      },
      "source": [
        "**Perceptron Question 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaOsKG9jEQtd",
        "outputId": "4bfd06f8-0834-4706-f8b9-941f2cdbb48a"
      },
      "source": [
        "list = []\n",
        "\n",
        "for x1, x2, label in df:\n",
        "    l = []\n",
        "    l.append(x1 * x1);\n",
        "    l.append(x2 * x2);\n",
        "    l.append(x1 * x2);\n",
        "    l.append(x1);\n",
        "    l.append(x2);\n",
        "    l.append(1);\n",
        "    l.append(label);\n",
        "    list.append(l)\n",
        "a = np.array(list)\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.    1.    1.    1.    1.    1.    1.  ]\n",
            " [ 1.    1.   -1.    1.   -1.    1.    1.  ]\n",
            " [16.   25.   20.    4.    5.    1.    1.  ]\n",
            " [ 4.    6.25  5.    2.    2.5   1.    2.  ]\n",
            " [ 0.    4.    0.    0.    2.    1.    2.  ]\n",
            " [ 4.    9.    6.    2.    3.    1.    2.  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcfVtWTKF5Cl",
        "outputId": "da2947bb-5ba8-468d-f210-eb79401f7b14"
      },
      "source": [
        "list = []\n",
        "for data in a:\n",
        "    if data[6] == 2:\n",
        "        data = np.multiply(data, -1)\n",
        "        list.append(data)\n",
        "    else:\n",
        "        list.append(data)\n",
        "\n",
        "a = np.array(list)\n",
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.  ,  1.  ,  1.  ,  1.  ,  1.  ,  1.  ,  1.  ],\n",
              "       [ 1.  ,  1.  , -1.  ,  1.  , -1.  ,  1.  ,  1.  ],\n",
              "       [16.  , 25.  , 20.  ,  4.  ,  5.  ,  1.  ,  1.  ],\n",
              "       [-4.  , -6.25, -5.  , -2.  , -2.5 , -1.  , -2.  ],\n",
              "       [-0.  , -4.  , -0.  , -0.  , -2.  , -1.  , -2.  ],\n",
              "       [-4.  , -9.  , -6.  , -2.  , -3.  , -1.  , -2.  ]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cm863bkkHQzU",
        "outputId": "76ab28a4-17fa-4fe9-8c66-479f22aa4916"
      },
      "source": [
        "a = a[:, 0:6]\n",
        "\n",
        "#print(a)\n",
        "\n",
        "alphas = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]);\n",
        "manyItcount = []\n",
        "oneItcount = []\n",
        "\n",
        "for alpha in alphas:\n",
        "    w = np.ones(6);\n",
        "    #print(w)\n",
        "    sum = np.zeros(6);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SnK8aXKJxfp"
      },
      "source": [
        "**Rest of the Question**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-3a6eh607KzW",
        "outputId": "a45250c9-b989-49b6-d414-18052ea8acd1"
      },
      "source": [
        "a = a[:, 0:6]\n",
        "\n",
        "print(a)\n",
        "\n",
        "alphas = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]);\n",
        "manyItcount = []\n",
        "oneItcount = []\n",
        "\n",
        "for alpha in alphas:\n",
        "    w = np.ones(6);\n",
        "    # print(w)\n",
        "    sum = np.zeros(6);\n",
        "\n",
        "    for i in range(500):\n",
        "        flag = 0;\n",
        "        for y in a:\n",
        "            val = np.dot(y, w)\n",
        "            if val <= 0:\n",
        "                flag = 1;\n",
        "                sum = np.add(y, sum)\n",
        "\n",
        "        w = w + sum * alpha\n",
        "        if flag == 0:\n",
        "            break;\n",
        "\n",
        "    manyItcount.append(i + 1)\n",
        "\n",
        "for alpha in alphas:\n",
        "    w = np.ones(6);\n",
        "    # print(w)\n",
        "\n",
        "    for i in range(500):\n",
        "        flag = 0;\n",
        "        for y in a:\n",
        "            val = np.dot(y, w)\n",
        "            if val <= 0:\n",
        "                flag = 1;\n",
        "                w = w + alpha * y\n",
        "\n",
        "        if flag == 0:\n",
        "            break;\n",
        "\n",
        "    oneItcount.append(i + 1)\n",
        "\n",
        "# print(oneItcount)\n",
        "\n",
        "print('Initial Weight vector all one: ')\n",
        "print('Alpha\\tOne At a Time\\tMany at a time')\n",
        "\n",
        "for i in range(len(alphas)):\n",
        "    print(alphas[i], '\\t\\t', oneItcount[i], '\\t', manyItcount[i])\n",
        "\n",
        "manyItcount = []\n",
        "oneItcount = []\n",
        "\n",
        "for alpha in alphas:\n",
        "    w = np.zeros(6);\n",
        "    # print(w)\n",
        "    sum = np.zeros(6);\n",
        "\n",
        "    for i in range(500):\n",
        "        flag = 0;\n",
        "        for y in a:\n",
        "            val = np.dot(y, w)\n",
        "            if val <= 0:\n",
        "                flag = 1;\n",
        "                sum = np.add(y, sum)\n",
        "\n",
        "        w = w + sum * alpha\n",
        "        if flag == 0:\n",
        "            break;\n",
        "\n",
        "    manyItcount.append(i + 1)\n",
        "\n",
        "for alpha in alphas:\n",
        "    w = np.zeros(6);\n",
        "    # print(w)\n",
        "\n",
        "    for i in range(500):\n",
        "        flag = 0;\n",
        "        for y in a:\n",
        "            val = np.dot(y, w)\n",
        "            if val <= 0:\n",
        "                flag = 1;\n",
        "                w = w + alpha * y\n",
        "\n",
        "        if flag == 0:\n",
        "            break;\n",
        "\n",
        "    oneItcount.append(i + 1)\n",
        "\n",
        "# print(oneItcount)\n",
        "\n",
        "print('Initial Weight vector all zero: ')\n",
        "\n",
        "print('Alpha\\tOne At a Time\\tMany at a time')\n",
        "\n",
        "for i in range(len(alphas)):\n",
        "    print(alphas[i], '\\t\\t', oneItcount[i], '\\t', manyItcount[i])\n",
        "\n",
        "manyItcount = []\n",
        "oneItcount = []\n",
        "\n",
        "for alpha in alphas:\n",
        "    w = random.sample(range(100), 6);\n",
        "    w = np.array(w)\n",
        "    # print(w)\n",
        "    sum = np.zeros(6);\n",
        "\n",
        "    for i in range(500):\n",
        "        flag = 0;\n",
        "        for y in a:\n",
        "            val = np.dot(y, w)\n",
        "            if val <= 0:\n",
        "                flag = 1;\n",
        "                sum = np.add(y, sum)\n",
        "\n",
        "        w = w + sum * alpha\n",
        "        if flag == 0:\n",
        "            break;\n",
        "\n",
        "    manyItcount.append(i + 1)\n",
        "\n",
        "for alpha in alphas:\n",
        "    w = random.sample(range(100), 6);\n",
        "    w = np.array(w)\n",
        "    # print(w)\n",
        "\n",
        "    for i in range(500):\n",
        "        flag = 0;\n",
        "        for y in a:\n",
        "            val = np.dot(y, w)\n",
        "            if val <= 0:\n",
        "                flag = 1;\n",
        "                w = w + alpha * y\n",
        "\n",
        "        if flag == 0:\n",
        "            break;\n",
        "\n",
        "    oneItcount.append(i + 1)\n",
        "\n",
        "# print(oneItcount)\n",
        "\n",
        "print('Initial Weight vector all random: ')\n",
        "\n",
        "print('Alpha\\tOne At a Time\\tMany at a time')\n",
        "\n",
        "for i in range(len(alphas)):\n",
        "    print(alphas[i], '\\t\\t', oneItcount[i], '\\t', manyItcount[i])\n",
        "\n",
        "\n",
        "for data in df:\n",
        "    if data[2] == 1:\n",
        "        plt.scatter(data[0], data[1], marker='*', color='red')\n",
        "    else:\n",
        "        plt.scatter(data[0], data[1], marker='+', color='blue')\n",
        "\n",
        "list = []\n",
        "\n",
        "for x1, x2, label in df:\n",
        "    l = []\n",
        "    l.append(x1 * x1);\n",
        "    l.append(x2 * x2);\n",
        "    l.append(x1 * x2);\n",
        "    l.append(x1);\n",
        "    l.append(x2);\n",
        "    l.append(1);\n",
        "    l.append(label);\n",
        "    list.append(l)\n",
        "\n",
        "a = np.array(list)\n",
        "print(a)\n",
        "list = []\n",
        "for data in a:\n",
        "    if data[6] == 2:\n",
        "        data = np.multiply(data, -1)\n",
        "        list.append(data)\n",
        "    else:\n",
        "        list.append(data)\n",
        "\n",
        "a = np.array(list)\n",
        "print(a)\n",
        "\n",
        "a = a[:, 0:6]\n",
        "\n",
        "print(a)\n",
        "\n",
        "alphas = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]);\n",
        "manyItcount = []\n",
        "oneItcount = []\n",
        "\n",
        "for alpha in alphas:\n",
        "    w = np.ones(6);\n",
        "    # print(w)\n",
        "    sum = np.zeros(6);\n",
        "\n",
        "    for i in range(500):\n",
        "        flag = 0;\n",
        "        for y in a:\n",
        "            val = np.dot(y, w)\n",
        "            if val <= 0:\n",
        "                flag = 1;\n",
        "                sum = np.add(y, sum)\n",
        "\n",
        "        w = w + sum * alpha\n",
        "        if flag == 0:\n",
        "            break;\n",
        "\n",
        "    manyItcount.append(i + 1)\n",
        "\n",
        "for alpha in alphas:\n",
        "    w = np.ones(6);\n",
        "    # print(w)\n",
        "\n",
        "    for i in range(500):\n",
        "        flag = 0;\n",
        "        for y in a:\n",
        "            val = np.dot(y, w)\n",
        "            if val <= 0:\n",
        "                flag = 1;\n",
        "                w = w + alpha * y\n",
        "\n",
        "        if flag == 0:\n",
        "            break;\n",
        "\n",
        "    oneItcount.append(i + 1)\n",
        "\n",
        "# print(oneItcount)\n",
        "\n",
        "print('Initial Weight vector all one: ')\n",
        "print('Alpha\\tOne At a Time\\tMany at a time')\n",
        "\n",
        "for i in range(len(alphas)):\n",
        "    print(alphas[i], '\\t\\t', oneItcount[i], '\\t', manyItcount[i])\n",
        "\n",
        "manyItcount = []\n",
        "oneItcount = []\n",
        "\n",
        "for alpha in alphas:\n",
        "    w = np.zeros(6);\n",
        "    # print(w)\n",
        "    sum = np.zeros(6);\n",
        "\n",
        "    for i in range(500):\n",
        "        flag = 0;\n",
        "        for y in a:\n",
        "            val = np.dot(y, w)\n",
        "            if val <= 0:\n",
        "                flag = 1;\n",
        "                sum = np.add(y, sum)\n",
        "\n",
        "        w = w + sum * alpha\n",
        "        if flag == 0:\n",
        "            break;\n",
        "\n",
        "    manyItcount.append(i + 1)\n",
        "\n",
        "for alpha in alphas:\n",
        "    w = np.zeros(6);\n",
        "    # print(w)\n",
        "\n",
        "    for i in range(500):\n",
        "        flag = 0;\n",
        "        for y in a:\n",
        "            val = np.dot(y, w)\n",
        "            if val <= 0:\n",
        "                flag = 1;\n",
        "                w = w + alpha * y\n",
        "\n",
        "        if flag == 0:\n",
        "            break;\n",
        "\n",
        "    oneItcount.append(i + 1)\n",
        "\n",
        "# print(oneItcount)\n",
        "\n",
        "print('Initial Weight vector all zero: ')\n",
        "\n",
        "print('Alpha\\tOne At a Time\\tMany at a time')\n",
        "\n",
        "for i in range(len(alphas)):\n",
        "    print(alphas[i], '\\t\\t', oneItcount[i], '\\t', manyItcount[i])\n",
        "\n",
        "manyItcount = []\n",
        "oneItcount = []\n",
        "\n",
        "for alpha in alphas:\n",
        "    w = random.sample(range(100), 6);\n",
        "    w = np.array(w)\n",
        "    # print(w)\n",
        "    sum = np.zeros(6);\n",
        "\n",
        "    for i in range(500):\n",
        "        flag = 0;\n",
        "        for y in a:\n",
        "            val = np.dot(y, w)\n",
        "            if val <= 0:\n",
        "                flag = 1;\n",
        "                sum = np.add(y, sum)\n",
        "\n",
        "        w = w + sum * alpha\n",
        "        if flag == 0:\n",
        "            break;\n",
        "\n",
        "    manyItcount.append(i + 1)\n",
        "\n",
        "for alpha in alphas:\n",
        "    w = random.sample(range(100), 6);\n",
        "    w = np.array(w)\n",
        "    # print(w)\n",
        "\n",
        "    for i in range(500):\n",
        "        flag = 0;\n",
        "        for y in a:\n",
        "            val = np.dot(y, w)\n",
        "            if val <= 0:\n",
        "                flag = 1;\n",
        "                w = w + alpha * y\n",
        "\n",
        "        if flag == 0:\n",
        "            break;\n",
        "\n",
        "    oneItcount.append(i + 1)\n",
        "\n",
        "# print(oneItcount)\n",
        "\n",
        "print('Initial Weight vector all random: ')\n",
        "\n",
        "print('Alpha\\tOne At a Time\\tMany at a time')\n",
        "\n",
        "for i in range(len(alphas)):\n",
        "    print(alphas[i], '\\t\\t', oneItcount[i], '\\t', manyItcount[i])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.    1.    1.    1.    1.    1.    1.  ]\n",
            " [ 1.    1.   -1.    1.   -1.    1.    1.  ]\n",
            " [16.   25.   20.    4.    5.    1.    1.  ]\n",
            " [ 4.    6.25  5.    2.    2.5   1.    2.  ]\n",
            " [ 0.    4.    0.    0.    2.    1.    2.  ]\n",
            " [ 4.    9.    6.    2.    3.    1.    2.  ]]\n",
            "[[ 1.    1.    1.    1.    1.    1.    1.  ]\n",
            " [ 1.    1.   -1.    1.   -1.    1.    1.  ]\n",
            " [16.   25.   20.    4.    5.    1.    1.  ]\n",
            " [-4.   -6.25 -5.   -2.   -2.5  -1.   -2.  ]\n",
            " [-0.   -4.   -0.   -0.   -2.   -1.   -2.  ]\n",
            " [-4.   -9.   -6.   -2.   -3.   -1.   -2.  ]]\n",
            "[[ 1.    1.    1.    1.    1.    1.  ]\n",
            " [ 1.    1.   -1.    1.   -1.    1.  ]\n",
            " [16.   25.   20.    4.    5.    1.  ]\n",
            " [-4.   -6.25 -5.   -2.   -2.5  -1.  ]\n",
            " [-0.   -4.   -0.   -0.   -2.   -1.  ]\n",
            " [-4.   -9.   -6.   -2.   -3.   -1.  ]]\n",
            "Initial Weight vector all one: \n",
            "Alpha\tOne At a Time\tMany at a time\n",
            "0.1 \t\t 6 \t 84\n",
            "0.2 \t\t 92 \t 68\n",
            "0.3 \t\t 104 \t 92\n",
            "0.4 \t\t 106 \t 94\n",
            "0.5 \t\t 93 \t 74\n",
            "0.6 \t\t 93 \t 73\n",
            "0.7 \t\t 108 \t 73\n",
            "0.8 \t\t 115 \t 67\n",
            "0.9 \t\t 94 \t 67\n",
            "1.0 \t\t 94 \t 67\n",
            "Initial Weight vector all zero: \n",
            "Alpha\tOne At a Time\tMany at a time\n",
            "0.1 \t\t 94 \t 61\n",
            "0.2 \t\t 94 \t 61\n",
            "0.3 \t\t 94 \t 61\n",
            "0.4 \t\t 94 \t 61\n",
            "0.5 \t\t 94 \t 61\n",
            "0.6 \t\t 94 \t 61\n",
            "0.7 \t\t 94 \t 61\n",
            "0.8 \t\t 94 \t 61\n",
            "0.9 \t\t 94 \t 61\n",
            "1.0 \t\t 94 \t 61\n",
            "Initial Weight vector all random: \n",
            "Alpha\tOne At a Time\tMany at a time\n",
            "0.1 \t\t 267 \t 270\n",
            "0.2 \t\t 163 \t 245\n",
            "0.3 \t\t 147 \t 143\n",
            "0.4 \t\t 47 \t 180\n",
            "0.5 \t\t 50 \t 138\n",
            "0.6 \t\t 19 \t 109\n",
            "0.7 \t\t 99 \t 81\n",
            "0.8 \t\t 12 \t 92\n",
            "0.9 \t\t 22 \t 93\n",
            "1.0 \t\t 33 \t 111\n",
            "[[ 1.    1.    1.    1.    1.    1.    1.  ]\n",
            " [ 1.    1.   -1.    1.   -1.    1.    1.  ]\n",
            " [16.   25.   20.    4.    5.    1.    1.  ]\n",
            " [ 4.    6.25  5.    2.    2.5   1.    2.  ]\n",
            " [ 0.    4.    0.    0.    2.    1.    2.  ]\n",
            " [ 4.    9.    6.    2.    3.    1.    2.  ]]\n",
            "[[ 1.    1.    1.    1.    1.    1.    1.  ]\n",
            " [ 1.    1.   -1.    1.   -1.    1.    1.  ]\n",
            " [16.   25.   20.    4.    5.    1.    1.  ]\n",
            " [-4.   -6.25 -5.   -2.   -2.5  -1.   -2.  ]\n",
            " [-0.   -4.   -0.   -0.   -2.   -1.   -2.  ]\n",
            " [-4.   -9.   -6.   -2.   -3.   -1.   -2.  ]]\n",
            "[[ 1.    1.    1.    1.    1.    1.  ]\n",
            " [ 1.    1.   -1.    1.   -1.    1.  ]\n",
            " [16.   25.   20.    4.    5.    1.  ]\n",
            " [-4.   -6.25 -5.   -2.   -2.5  -1.  ]\n",
            " [-0.   -4.   -0.   -0.   -2.   -1.  ]\n",
            " [-4.   -9.   -6.   -2.   -3.   -1.  ]]\n",
            "Initial Weight vector all one: \n",
            "Alpha\tOne At a Time\tMany at a time\n",
            "0.1 \t\t 6 \t 84\n",
            "0.2 \t\t 92 \t 68\n",
            "0.3 \t\t 104 \t 92\n",
            "0.4 \t\t 106 \t 94\n",
            "0.5 \t\t 93 \t 74\n",
            "0.6 \t\t 93 \t 73\n",
            "0.7 \t\t 108 \t 73\n",
            "0.8 \t\t 115 \t 67\n",
            "0.9 \t\t 94 \t 67\n",
            "1.0 \t\t 94 \t 67\n",
            "Initial Weight vector all zero: \n",
            "Alpha\tOne At a Time\tMany at a time\n",
            "0.1 \t\t 94 \t 61\n",
            "0.2 \t\t 94 \t 61\n",
            "0.3 \t\t 94 \t 61\n",
            "0.4 \t\t 94 \t 61\n",
            "0.5 \t\t 94 \t 61\n",
            "0.6 \t\t 94 \t 61\n",
            "0.7 \t\t 94 \t 61\n",
            "0.8 \t\t 94 \t 61\n",
            "0.9 \t\t 94 \t 61\n",
            "1.0 \t\t 94 \t 61\n",
            "Initial Weight vector all random: \n",
            "Alpha\tOne At a Time\tMany at a time\n",
            "0.1 \t\t 379 \t 285\n",
            "0.2 \t\t 80 \t 135\n",
            "0.3 \t\t 203 \t 167\n",
            "0.4 \t\t 36 \t 105\n",
            "0.5 \t\t 45 \t 109\n",
            "0.6 \t\t 34 \t 108\n",
            "0.7 \t\t 55 \t 53\n",
            "0.8 \t\t 35 \t 142\n",
            "0.9 \t\t 40 \t 10\n",
            "1.0 \t\t 26 \t 102\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}